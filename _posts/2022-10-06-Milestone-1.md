---
layout: post
title: Milestone 1
---


## <span style="color:SlateBlue;">Q1: Data Aquisation</span>
The Data Aquisation code in written in the get_data.py file which consists of a few functions that I will discuss each below:



**`get_data_regular(year, file_path)`**





This function takes as input a year representing a season and a file path and downloads all the liveData and GameData events of the regular season in the file_path.
It first checks whether the data for the requested season exists or not: If it is already downloaded in the file_path, it will just load it. Else it will start downloading the data.
### How does it download the requested data?

 1. First we need to specify the GAME_ID in the following URL to be able to download the data:
 https://statsapi.web.nhl.com/api/v1/game/[GAME_ID]/feed/live/

	We know that GAME_ID for a regular season is created like this:
	4 digits for the season year + 02 + 4 digits for specific game number.
So the first game of the season 2016-2017 will have GAME_ID of 2016020001.

	This is how we create the GAME_ID in this function:

	    GAME_ID = "{}02{:04d}".format(year, i)

	i is specific number of the game.

	Using this, we can create the GAME_IDs for each season and we only need to increase the GAME_ID by 1 to go to the next game.


	#### When do we know if we have downloaded all the games?

	We stop downloading data from a given season when we reach a GAME_ID that has no liveData in its URL. It means that game is not available, and so other game s with higher GAME_IDs will not be available as well.

 2. Now that we know what GAME_ID to use, we will start downloading.
Using the GAME_ID we have, we can substitude it in the URL we have:

		`url='https://statsapi.web.nhl.com/api/v1/game/{}/feed/live/'.format(GAME_ID)`

	We can now download the data in this URL using the ***request*** library and save it as a json file.

		r = requests.get(url).json()

	This way we can have all the data in the url in r.



 3. In this part we can check to see whether liveData exists for this 			GAME_ID or not.  As said before, if it doesnt, we should end our downloading. But if it does, we save the data in a dictionary called **all_regular_games** with the key being GAME_ID.

	 We dont save all the r data we have as we don't need many parts. We just save gameData and liveData from each valid url and save them as in a dictionary called **regular_game** as below:


		regular_game['gameData'], regular_game['liveData'] = r['gameData'], r['liveData']
	Them we add this dictionary as value of the GAME_ID key to our main dictionary called **all_regular_games**:


	    all_regular_games[GAME_ID] = regular_game



At the end when we finish downloading all we needed, we now have all the data in **all_regular_games** dictionary.
Now we should just save this data in a json file using **json** library.

    with open(file_path, 'w') as f_regular:
	    json.dump(all_regular_games, f_regular)


The second function works the same as the first function, but it downloads the data for the playoff games.

**`def get_data_playoffs(year, file_path)`**

All the steps for this function is the same as the **get_data_regular** function. But there is a little difference in the way we compute GAME_ID which i will discuss below:
We know that GAME_ID for a playoff game is created like below:

4 digits for the season year + 030 + 3 digits for specific number of the game.
Specific number of the game is created like this:
1 digit for the round of the playoffs + 1 digit for the matchup + 1 digit for the game (out of 7)
So the first game of the first matchup of the first round of the season 2016-2017 will have GAME_ID of 2016030111

We know that there are 4 rounds in each playoff. So the first digit of the specific game number will be from 1 to 4.
We also know that in the first round we will have 16 teams to compete. So there will be 8 matchups(2^(4-1)).
Then for the second round we have 8 teams to compete. So there will be 4 matchups(2^(4-2)).
For the thirds and forth round we have 4 and 2 teams respectively ans therefore there will be 2 matchups for the third round(2^(4-3)) and 1 matchup for the last round(2^(4-4)).
So we can define the maximum number of matchups available for each round as below:

    2 ** (4 - number of round)

  So this way we can specify the range available for the second digit of our specific game number to be from 1 to (2 ** (4 - number of round)).

Finally we know that maximum number of the games in each matchup is 7. So the third digit in the specific game number will be from 1 to 7.

Now we can easily make GAME_IDs for a playoff game and download their URL like before:
 We should just go through a for loop from **1 to 4 as the round number**(for the first digit of the specific game number), and have another for loop **from 1 to (2 ** (4 - number of round)) for number of the matchup** (the second digit of the specific game number) and the last loop **from 1 to 7 specifying number of the game** in that matchup( third digit of the specific game number). In side the third loop we will create the GAME_ID and the url like below:


    GAME_ID = '{}030{}{}{}'.format(year, p_round, match_up, game)
	url = 'https://statsapi.web.nhl.com/api/v1/game/{}/feed/live/'.format(GAME_ID)

p_round is the round number, match_up is the matchup number and game is the game number in that matchup.

We can now download our data using **request** library and if the liveData exists, we save the data in the dictionary format explained before(we will save data in **all_playoff_games** dictionary). If not, we will skip saving and will move on to the next itereation available.

At the final step we save the **all_playoff_games** to a json file like before.

Now we just need a main function to make everything work together

    main()

  We specify the following variables:


 - path: is the path where our downloaded files will be saved
 - year: is the start year
 - to_year: is the last year

  So when we want to download data of the years 2016 to 2021 we should specify year = 2019 and to_year = 2021.

  Then in a for loop in the range of (year, to_year+1) we call :
  We make a name for the our output file.
  For regular season data in year "y" we have this name:

    file_path_regular = path + "/" + str(y) + "_regular_season.json"
 And for a playoff game data in the year "y" it will be:


    file_path_playoff = path + "/" + str(  y) + "_playoffs.json"
And at the last step we call the 2 functions we wrote:

    get_data_playoffs(y, file_path_playoff)
    get_data_regular(y, file_path_regular)


## <span style="color:SlateBlue;">Q2: Interactive Debugging Tool</span>

<!--Combined Image of whole ipywidgets-->
![ipywidgets](../public/Ipywidgets.png)


The image above displays the interactive ipywidget tool to extract information using the following:
- The Season can be shifted between "Playoffs" and "Regular season" using radiobutton.
- Based on the season selected, the gameId IntSlider values change and hence you can slide to see the information about that particular gameId. The information includes Game start date , game Id , which two teams are playing, Goals, Shot On Goals and SO Goals.
- Based on the gameId, the slider value of the eventId changes.
- According to the eventId selected, we plot the x and y coordinates of the event on the ice rink.
- The rest of the information<!--Include the information required--> is displayed according to the selected event id.

The code for the tool is as follows:<!--Combine the code and then add it-->

	def game_id_info(year,season):
    """"
    Widgets to select game id and season id and display game information
    """
    global paths
    paths = 'data/'+year+'_'+season+'.json'
    
    """Select the season through season widget"""
    season_widget = widgets.RadioButtons(
        options=['regular_season', 'playoffs'],
        description='Season:',
        disabled=False,
        )
    global path_new

    def get_game_ids(path_new):
        """returns a list of all game ids inside a json file"""
        game_ids = []
        with open(path_new) as json_file:
            if re.search('regular_season', path_new):
                data = json.load(json_file)
                game_ids = list(data.keys())
            elif re.search('playoffs', path_new):
                data = json.load(json_file)
                game_ids = list(data.keys())
                print(game_ids)
                # check if the game id is not in playoffs json file, then do not add it to the list
                for game_id in game_ids:
                    if game_id not in data.keys():
                        game_ids.remove(game_id)
        return game_ids
        
    path_new=paths

    def on_season_widget_change(change):
        """When there is a change in the season widget, update the game id widget"""
        global path_new
        # print("Value of season widget is: ",season_widget.value)
        if change['new'] == 'playoffs':
            season = 'playoffs'
            path_new = 'data/'+year+'_playoffs.json'
            id_widget.max = get_game_ids(path_new)[-1]
            id_widget.min = get_game_ids(path_new)[0]
            id_widget.options = get_game_ids(path_new)
        elif change['new'] == 'regular_season':
            season = 'regular_season'
            path_new = 'data/'+year+'_regular_season.json'
            id_widget.max = get_game_ids(path_new)[-1]
            id_widget.min = get_game_ids(path_new)[0]
            id_widget.options = get_game_ids(path_new)
        else:
            print("Error")

    """Game id widget to select game id""" 
    id_widget = widgets.SelectionSlider(
            # value=MIN_ID,
            min=get_game_ids(path_new)[0],
            max=get_game_ids(path_new)[-1],
            # step=1,
            options = get_game_ids(path_new),
            description='game_id:',
            continuous_update=False
        )

    def display_details(game_id):
        """displays the information of the game id selected"""
        with open(path_new) as json_file:
            data = json.load(json_file)
            game = data[str(game_id)]
            a = "Game Start Date: " + game['gameData']['datetime']['dateTime']
            b = "Game ID: " + str(game_id)+"; "+game['gameData']['teams']['home']['abbreviation']+" (home) vs "+game['gameData']['teams']['away']['abbreviation']+" (away)"
            # Display the 2 teams information in a form of a dataframe
            df = pd.DataFrame({'Team': [game['gameData']['teams']['home']['abbreviation'], game['gameData']['teams']['away']['abbreviation']],
                                'Goals': [game['liveData']['linescore']['teams']['home']['goals'], game['liveData']['linescore']['teams']['away']['goals']],
                                'SOG': [game['liveData']['linescore']['teams']['home']['shotsOnGoal'], game['liveData']['linescore']['teams']['away']['shotsOnGoal']],
                                'SO Goals': [game['liveData']['linescore']['teams']['home']['powerPlay'], game['liveData']['linescore']['teams']['away']['powerPlay']],
                                #'SO Attempts': [game['liveData']['linescore']['teams']['home']['powerPlayOpportunities'], game['liveData']['linescore']['teams']['away']['powerPlayOpportunities']]
                                })
            display(a)
            display(b)
            display(df)

    season_widget.observe(on_season_widget_change, names='value')
    display(season_widget)
    # print("Value of season widget is: ",season_widget.value)
    widgets.interact(display_details, game_id=id_widget)


## <span style="color:SlateBlue;">Q3: Tidy Data</span>


## <span style="color:SlateBlue;">Q4: Simple Visualization</span>
